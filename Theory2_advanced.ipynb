{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFU+af63e/CMtpIOO+zyCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaysuseel/PyTorch-start/blob/main/Theory2_advanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Advanced Computer Vision\n",
        "\n",
        "https://saisriteja.github.io/TKMCE_Pixels_To_Paper/"
      ],
      "metadata": {
        "id": "p1Jgtqj9Wq8a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AxXXxhcdW3Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----NeRF\n",
        "\n",
        "----GAURA\n",
        "\n",
        "----text to 4D rendering\n",
        "\n",
        "----PaintScene4D\n",
        "\n",
        "----Single Photon Camera\n",
        "\n",
        "----PhotonSplat\n",
        "\n",
        "----Integrating SPAD camera into 3D systems\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "raL9gq-vY6hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "0r_Boez-azK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----DIVA(ECCV 2024)----scribble map\n",
        "\n",
        "----Text to sign language\n",
        "\n",
        "----Flare removal(FRU-GAN)\n",
        "\n",
        "----Image inpainting"
      ],
      "metadata": {
        "id": "hwoy8q4EbCEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introduction to CV"
      ],
      "metadata": {
        "id": "hIH0ljV6dKeb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Neuroscience in CV\n",
        "\n",
        "----Edge detection\n",
        "\n",
        "----Harris Corner\n",
        "\n",
        "----SIFT\n",
        "\n",
        "----Feature extraction with DL\n",
        "\n",
        "----Object detection\n",
        "\n",
        "----Segmentation\n",
        "\n",
        "----Image Restoration\n",
        "\n",
        "    ----Image deblurring\n",
        "\n",
        "    ----Super resolution\n",
        "\n",
        "----Computational Imaging\n",
        "\n",
        "----Text+Image\n",
        "\n",
        "    ----Image Retrieval\n",
        "\n",
        "    ----Captioning\n",
        "\n",
        "    ----VQA(cross checking model)\n",
        "\n",
        "    ----OCR\n",
        "\n",
        "    ----CLIP(text+image)\n",
        "\n",
        "    ----LLM + Vision\n",
        "\n",
        "    ----LlaVA\n",
        "\n",
        "    ----Zero and few shot(learning by showing)\n",
        "\n",
        "----Foundation Models in CV\n",
        "\n",
        "    ----Textually Prompted Models\n",
        "\n",
        "    ----Visually Prompted Models\n",
        "\n",
        "----Generative AI(image and 3D)\n",
        "\n",
        "    ----images from image as prior\n",
        "\n",
        "    ----images from text as prior(DALL-E ,stable diffusion)\n",
        "\n"
      ],
      "metadata": {
        "id": "5s7pMm51duza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----CLIP :cosine similarity\n",
        "----Start with simple datasets and newer ideas for demonstration"
      ],
      "metadata": {
        "id": "p20LnTokjxBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ViTs"
      ],
      "metadata": {
        "id": "i9mN4ZqBmKdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----RNNs to Transformers\n",
        "\n",
        "    ----Localization and single direction context\n",
        "\n",
        "    ----CNNs + ResNets\n",
        "    ----RNNs + LSTMs\n",
        "\n",
        "    ----Transformers learn inductive bias\n",
        "\n",
        "    ----Encoder/Decoder\n",
        "\n",
        "    ----Attention\n",
        "\n",
        "    ----Learning embeddings for words by masking\n",
        "\n",
        "    ----Cross Attention and Self Attention"
      ],
      "metadata": {
        "id": "hkIIO_QtmPhI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----An Image is Worth 16*16 Words :Transformers for Image Recognition at Scale\n",
        "\n",
        "----contextualizing info from other patches to current patch\n",
        "\n",
        "----CLS token\n",
        "\n",
        "----localization bias in patches is removed by CLS token\n",
        "\n",
        "----positional embeddings\n",
        "\n",
        "----Data intensive transformers(bigger data,better model)\n",
        "\n",
        "----Load pretrained model and finetune\n",
        "\n",
        "----patches to classes"
      ],
      "metadata": {
        "id": "lz5iYaeAy72-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Self Supervised Learning"
      ],
      "metadata": {
        "id": "kssQbWVe3Qg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----DINO\n",
        "\n",
        "----Dense Attention maps\n",
        "\n",
        "----Self Supervised Learning With Knowledge Distillation\n",
        "\n",
        "----MLP layer\n",
        "\n"
      ],
      "metadata": {
        "id": "V2bdrA233VL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text To Image Generation"
      ],
      "metadata": {
        "id": "U4TRsF_48U6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----inefficiency of pure ViTs in image generation\n",
        "\n",
        "----Stable Diffusion vs Attend and Excite\n",
        "\n",
        "----Stable Diffusion with Attend and Excite\n",
        "\n",
        "----forcing a model to give all words equal attention\n",
        "\n",
        "----Video::Space Time Attention\n",
        "\n",
        "----Point Cloud Understanding\n",
        "\n",
        "----Transformers in 3D vision models(Depth)"
      ],
      "metadata": {
        "id": "I3cneArq8Xmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Session end!!\")"
      ],
      "metadata": {
        "id": "zNLXNDWR3Bu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Diffusion Models"
      ],
      "metadata": {
        "id": "RUFfNNOamBvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Gaussian Distribution\n",
        "\n",
        "----VAE(Variational Auto Encoder)\n",
        "\n",
        "----GAN\n",
        "\n",
        "    ----Generator and Discriminator\n",
        "\n",
        "    ----Model collapse"
      ],
      "metadata": {
        "id": "KFU13nO9mFqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Diffusion Architecture\n"
      ],
      "metadata": {
        "id": "3qCYzZVRo83Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Gaussian Space\n",
        "\n",
        "----Markovian Chain\n",
        "\n",
        "----Latent Diffusion(Reducing images to smaller size)\n",
        "\n",
        "----DDPM vs DDIM"
      ],
      "metadata": {
        "id": "MgmiF8t_pBPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Style Transfer\n",
        "\n",
        "    ----Text\n",
        "    \n",
        "    ----Image\n"
      ],
      "metadata": {
        "id": "0yEEJHAQ_m3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Neural Radiance Fields"
      ],
      "metadata": {
        "id": "3gstqmoBndbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Capturing reality\n",
        "\n",
        "----2D to 3D rendering\n",
        "\n",
        "----Standard coordinate based MLP cannot understand high frequencies\n",
        "\n",
        "----High Frequency Mapping\n",
        "\n",
        "----NeRF=Volume rendering + coordinate based network\n",
        "\n",
        "----Ray Tracing\n",
        "\n",
        "----Not generalizable\n",
        "\n",
        "----Is Attention All that NeRF needs.\n",
        "\n",
        "----Block-NeRF,Hypernerfs,NeRF in Wild,NeRF in the Dark\n",
        "\n",
        "----Text to 3D rendering\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yWMkF5RenjKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gaussian Splatting"
      ],
      "metadata": {
        "id": "r_hnlvwA_HUS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Motivation\n",
        "\n",
        "    ----3D Video Editing\n",
        "\n",
        "    ----Constructing real world scene from Img + Video\n",
        "\n",
        "----Surface Platting\n",
        "\n",
        "----3D Gaussian\n",
        "\n",
        "----Volume Splatting\n",
        "\n",
        "----COLMAP\n",
        "\n",
        "----Adaptive density control\n",
        "\n",
        "----More faster than NeRFs\n",
        "\n",
        "----Better Control"
      ],
      "metadata": {
        "id": "O19hL7JPAgLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Session Ends\")"
      ],
      "metadata": {
        "id": "lfW3uaNtMHeI",
        "outputId": "49271219-cfd8-454a-848d-a15d75c89d0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Session Ends\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Object Detection"
      ],
      "metadata": {
        "id": "Z0Kfi6srvikE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----CVAT AI::Annotation tool\n",
        "\n",
        "----Datasets::Roboflow,Kaggle,Hugging Face\n",
        "\n",
        "----Synthetic Datasets::Stable Diffusion,GAN\n",
        "\n",
        "----Ultralytics-Yolov5-->Yolov11\n",
        "\n",
        "----Nvidia Tow toolkit\n",
        "\n",
        "----**Autodistill**\n",
        "\n",
        "----Annotate 10000 objects manually and train Yolo on top"
      ],
      "metadata": {
        "id": "DGleQg0qvrYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Yolo folder format\n",
        "\n",
        "----Roboflow\n",
        "\n",
        "----https://public.roboflow.com/object-detection/aquarium\n",
        "\n",
        "----A.RandomSnow"
      ],
      "metadata": {
        "id": "d-BqxhTCxQXA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Point Cloud"
      ],
      "metadata": {
        "id": "TFRczq45WPuc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----W*H*3 in 2D to N*3 in point cloud(N points)\n",
        "\n",
        "----Coloured Point Clouds\n",
        "\n",
        "----Augmentation in Point Clouds\n",
        "\n",
        "    ----Rotation\n",
        "    ----Scale\n",
        "    ----Noise\n",
        "    ----Shift/Translation\n",
        "\n",
        "----Visualization::Meshlab\n",
        "\n",
        "    ----Classification\n",
        "    ----Part Segmentation\n",
        "    ----Semantic Segmentation\n",
        "\n",
        "----LiDAR sensors::Return Point Cloud Data\n",
        "\n",
        "----Text to Point Cloud Generation\n",
        "\n",
        "----Observers dataset\n",
        "\n",
        "----Image to Point Cloud Generation\n",
        "\n",
        "----Point Cloud Upsampling\n",
        "\n",
        "----Point Cloud Denoising\n",
        "\n",
        "----(.ply,.xyz) file"
      ],
      "metadata": {
        "id": "XxK4jATqXmUi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rtBg9xnPDq2F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}