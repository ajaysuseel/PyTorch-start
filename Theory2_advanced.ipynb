{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQfnQmIm1D3SGZolkKqDtA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajaysuseel/PyTorch-start/blob/main/Theory2_advanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Advanced Computer Vision"
      ],
      "metadata": {
        "id": "p1Jgtqj9Wq8a"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AxXXxhcdW3Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "----NeRF\n",
        "\n",
        "----GAURA\n",
        "\n",
        "----text to 4D rendering\n",
        "\n",
        "----PaintScene4D\n",
        "\n",
        "----Single Photon Camera\n",
        "\n",
        "----PhotonSplat\n",
        "\n",
        "----Integrating SPAD camera into 3D systems\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "raL9gq-vY6hc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----"
      ],
      "metadata": {
        "id": "0r_Boez-azK9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----DIVA(ECCV 2024)----scribble map\n",
        "\n",
        "----Text to sign language\n",
        "\n",
        "----Flare removal(FRU-GAN)\n",
        "\n",
        "----Image inpainting"
      ],
      "metadata": {
        "id": "hwoy8q4EbCEr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Introduction to CV"
      ],
      "metadata": {
        "id": "hIH0ljV6dKeb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Neuroscience in CV\n",
        "\n",
        "----Edge detection\n",
        "\n",
        "----Harris Corner\n",
        "\n",
        "----SIFT\n",
        "\n",
        "----Feature extraction with DL\n",
        "\n",
        "----Object detection\n",
        "\n",
        "----Segmentation\n",
        "\n",
        "----Image Restoration\n",
        "\n",
        "    ----Image deblurring\n",
        "\n",
        "    ----Super resolution\n",
        "\n",
        "----Computational Imaging\n",
        "\n",
        "----Text+Image\n",
        "\n",
        "    ----Image Retrieval\n",
        "\n",
        "    ----Captioning\n",
        "\n",
        "    ----VQA(cross checking model)\n",
        "\n",
        "    ----OCR\n",
        "\n",
        "    ----CLIP(text+image)\n",
        "\n",
        "    ----LLM + Vision\n",
        "\n",
        "    ----LlaVA\n",
        "\n",
        "    ----Zero and few shot(learning by showing)\n",
        "\n",
        "----Foundation Models in CV\n",
        "\n",
        "    ----Textually Prompted Models\n",
        "\n",
        "    ----Visually Prompted Models\n",
        "\n",
        "----Generative AI(image and 3D)\n",
        "\n",
        "    ----images from image as prior\n",
        "\n",
        "    ----images from text as prior(DALL-E ,stable diffusion)\n",
        "\n"
      ],
      "metadata": {
        "id": "5s7pMm51duza"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----CLIP :cosine similarity\n",
        "----Start with simple datasets and newer ideas for demonstration"
      ],
      "metadata": {
        "id": "p20LnTokjxBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ViTs"
      ],
      "metadata": {
        "id": "i9mN4ZqBmKdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----RNNs to Transformers\n",
        "\n",
        "    ----Localization and single direction context\n",
        "\n",
        "    ----CNNs + ResNets\n",
        "    ----RNNs + LSTMs\n",
        "\n",
        "    ----Transformers learn inductive bias\n",
        "\n",
        "    ----Encoder/Decoder\n",
        "\n",
        "    ----Attention\n",
        "\n",
        "    ----Learning embeddings for words by masking\n",
        "\n",
        "    ----Cross Attention and Self Attention"
      ],
      "metadata": {
        "id": "hkIIO_QtmPhI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----An Image is Worth 16*16 Words :Transformers for Image Recognition at Scale\n",
        "\n",
        "----contextualizing info from other patches to current patch\n",
        "\n",
        "----CLS token\n",
        "\n",
        "----localization bias in patches is removed by CLS token\n",
        "\n",
        "----positional embeddings\n",
        "\n",
        "----Data intensive transformers(bigger data,better model)\n",
        "\n",
        "----Load pretrained model and finetune\n",
        "\n",
        "----patches to classes"
      ],
      "metadata": {
        "id": "lz5iYaeAy72-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Self Supervised Learning"
      ],
      "metadata": {
        "id": "kssQbWVe3Qg5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----DINO\n",
        "\n",
        "----Dense Attention maps\n",
        "\n",
        "----Self Supervised Learning With Knowledge Distillation\n",
        "\n",
        "----MLP layer\n",
        "\n"
      ],
      "metadata": {
        "id": "V2bdrA233VL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text To Image Generation"
      ],
      "metadata": {
        "id": "U4TRsF_48U6A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----inefficiency of pure ViTs in image generation\n",
        "\n",
        "----Stable Diffusion vs Attend and Excite\n",
        "\n",
        "----Stable Diffusion with Attend and Excite\n",
        "\n",
        "----forcing a model to give all words equal attention\n",
        "\n",
        "----Video::Space Time Attention\n",
        "\n",
        "----Point Cloud Understanding\n",
        "\n",
        "----Transformers in 3D vision models(Depth)"
      ],
      "metadata": {
        "id": "I3cneArq8Xmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Session end!!\")"
      ],
      "metadata": {
        "id": "zNLXNDWR3Bu3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Diffusion Models"
      ],
      "metadata": {
        "id": "RUFfNNOamBvd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Gaussian Distribution\n",
        "\n",
        "----VAE(Variational Auto Encoder)\n",
        "\n",
        "----GAN\n",
        "\n",
        "    ----Generator and Discriminator\n",
        "\n",
        "    ----Model collapse"
      ],
      "metadata": {
        "id": "KFU13nO9mFqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Diffusion Architecture\n"
      ],
      "metadata": {
        "id": "3qCYzZVRo83Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Gaussian Space\n",
        "\n",
        "----Markovian Chain\n",
        "\n",
        "----Latent Diffusion(Reducing images to smaller size)\n",
        "\n",
        "----DDPM vs DDIM"
      ],
      "metadata": {
        "id": "MgmiF8t_pBPe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Style Transfer\n",
        "\n",
        "    ----Text\n",
        "    \n",
        "    ----Image\n"
      ],
      "metadata": {
        "id": "0yEEJHAQ_m3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Neural Radiance Fields"
      ],
      "metadata": {
        "id": "3gstqmoBndbK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "----Capturing reality\n",
        "\n",
        "----2D to 3D rendering\n",
        "\n",
        "----Standard coordinate based MLP cannot understand high frequencies\n",
        "\n",
        "----High Frequency Mapping\n",
        "\n",
        "----NeRF=Volume rendering + coordinate based network\n",
        "\n",
        "----Ray Tracing\n",
        "\n",
        "----Not generalizable\n",
        "\n",
        "----Is Attention All that NeRF needs.\n",
        "\n",
        "----Block-NeRF,Hypernerfs,NeRF in Wild,NeRF in the Dark\n",
        "\n",
        "----Text to 3D rendering\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yWMkF5RenjKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "r_hnlvwA_HUS"
      }
    }
  ]
}